{
    "collab_server" : "",
    "contents" : "# 欠損値とカテゴリカル変数をどうしましょう。\n# カテゴリカル変数はone hot encodingするようだ。\n\n# 初期化\nrm(list = ls())\ngc();gc()\n\n# パッケージ\nrequire(data.table)\nrequire(dplyr)\nrequire(xgboost)\nrequire(caret)\nrequire(tcltk)\n\n# データ加工----\n# データ読み込み\ndata.train.raw <- fread(\"inputs/train.csv\", data.table = F)\ndata.test.raw <- fread(\"inputs/test.csv\", data.table = F)\n# あとでデータを分割するために、行数を取得しておく\nn.train <- nrow(data.train.raw)\nn.test <- nrow(data.test.raw)\n# train, testをくっつける\ndata.full <- bind_rows(data.train.raw, data.test.raw)\n# 欠損を表す極端な値を入れておく\ndata.full[is.na(data.full)] <- -9999\n# one hot encoding\ndata.full.s.m.m <- sparse.model.matrix(Survived~.-1, data = data.full)\n# xgbに対応できるようにデータの型変換\ndata.full.xgbD <- xgb.DMatrix(data = data.full.s.m.m, missing = -9999, label = data.full$Survived)\n# train, testにデータを分割する\ntrain.xgbD <- slice(data.full.xgbD, 1:n.train)\ntest.xgbD <- slice(data.full.xgbD, (n.train+1):(n.train+n.test))\n\n# モデリング----\n# 事前設定パラメータ\ncv.nrounds <- 100\ncv.nfold <- 10\ncv.stopping <- 10\n# ハイパーパラメーター\nhyperparamerters <- expand.grid(\n  max_depth = seq(5, 15, by = 3),\n  eta = seq(0.01, 0.1, by = 0.001),\n  gamma = seq(1, 1.1, by = 0.2), \n  subsample = seq(1, 1.1, by = 0.2),\n  colsample_bytree = seq(1, 1.1, by = 0.2), \n  min_child_weight = seq(1, 1.1, by = 0.2),\n  max_delta_step = seq(1, 1.1, by = 0.2)\n)\nn.hyper <- nrow(hyperparamerters)\nv.hyper <- vector(length = n.hyper)\n# プログレスバー\npb <- txtProgressBar(min = 1, max = n.hyper, style = 3)\nfor(i in 1 : n.hyper){\n  setTxtProgressBar(pb, i) \n  param <- list(objective = \"binary:logistic\",\n                eval_metric = \"auc\",\n                max_depth = hyperparamerters$max_depth[i],\n                eta = hyperparamerters$eta[i],\n                gamma = hyperparamerters$gamma[i], \n                subsample = hyperparamerters$subsample[i],\n                colsample_bytree = hyperparamerters$colsample_bytree[i], \n                min_child_weight = hyperparamerters$min_child_weight[i],\n                max_delta_step = hyperparamerters$max_delta_step[i]\n  )\n  tmp.trained.model <- xgb.cv(data = train.xgbD, missing = -9999, nrounds = cv.nrounds\n                              , params = param, nfold = cv.nfold, early.stop.round = cv.stopping, verbose = F)\n  tmp.auc <- tmp.trained.model %>% summarise(max = max(test.auc.mean))\n  v.hyper[i] <- tmp.auc %>% as.numeric()\n}\nbest.hyper <- which.max(v.hyper)\nparam <- list(objective = \"binary:logistic\",\n              eval_metric = \"auc\",\n              max_depth = hyperparamerters$max_depth[best.hyper],\n              eta = hyperparamerters$eta[best.hyper],\n              gamma = hyperparamerters$gamma[best.hyper], \n              subsample = hyperparamerters$subsample[best.hyper],\n              colsample_bytree = hyperparamerters$colsample_bytree[best.hyper], \n              min_child_weight = hyperparamerters$min_child_weight[best.hyper],\n              max_delta_step = hyperparamerters$max_delta_step[best.hyper]\n)\ntrained.model <- xgboost(data = train.xgbD, missing = -9999, nrounds = cv.nrounds\n                            , params = param, nfold = cv.nfold, verbose = F, prediction = T)\nprediction.value <- predict(object = trained.model, test.xgbD)\npredition.01 <- ifelse(test = prediction.value > 0.5, 1, 0)\nprediction.test <- data.frame(PassengerId = data.test.raw$PassengerId, Survived = predition.01)\nwrite.csv(prediction.test, file = \"prediction.csv\", row.names = F)\n\n# 後処理----\n# importance\nimportance <- xgb.importance(data.full.s.m.m@Dimnames[[2]], model = trained.model)\nxgb.plot.importance(importance_matrix = importance)\n\n",
    "created" : 1477742028821.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1876280457",
    "id" : "77C6060D",
    "lastKnownWriteTime" : 1477780134,
    "last_content_update" : 1477780134822,
    "path" : "~/Projects/kaggle/titanic/00_xgb_sample.R",
    "project_path" : "00_xgb_sample.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}